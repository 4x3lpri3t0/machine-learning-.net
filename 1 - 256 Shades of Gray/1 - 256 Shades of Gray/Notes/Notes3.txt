=================================
Computing Distance between Images
=================================

What we want is a method that takes two arrays of pixels and returns a number
that describes how different they are.

Distance is an area of volatility in our algorithm; it is very likely that we will
want to experiment with different ways of comparing images to figure out what works
best, so putting in place a design that allows us to easily substitute various
distance definitions without requiring too many code changes is highly desirable.

An interface gives us a convenient mechanism by which to avoid tight coupling,
and to make sure that when we decide to change the distance code later,
we won’t run into annoying refactoring issues. (see IDistance)

MANHATTAN DISTANCE (aka "L1 Distance"):
Compare 2 images pixel by pixel, compute each difference,
and add up their absolute values.

====================
Writing a Classifier
====================

In every situation, we expect a two-step process:
We will train the classifier by feeding it a training set of known observations,
and once that is done, we will expect to be able to predict the label of an image.
(see IClassifier)

============================
So, How Do We Know It Works?
============================

================
Cross-validation
================

We could feed images to the classifier, ask for a prediction, compare it to the true answer,
and compute how many we got right.

That dataset is known as a VALIDATION SET (or "test data").

CROSS-VALIDATION:
Put aside part of the data you have available and split it into a training set and a validation set.
Use the 1º one to train your model and the 2º one to evaluate the quality of your model.

===================================
Evaluating the Quality of Our Model
===================================

(see Evaluator)
If we run this now -> 93.40% correct